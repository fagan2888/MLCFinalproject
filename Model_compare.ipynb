{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run codes with the notation \"#Run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from tensorboardX import SummaryWriter\n",
    "# writer = SummaryWriter()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run\n",
    "#citiDataRaw=pd.read_csv(\"citibike_final_sample.csv\")\n",
    "# citiDataRaw=pd.read_csv(\"citibike_final_sample.csv\")\n",
    "# citiDataRaw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Subtract the outlier for latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run\n",
    "# citiDataRaw = citiDataRaw[citiDataRaw['endstationlatitude']<45 ]\n",
    "# citiDataRaw = citiDataRaw[citiDataRaw['startstationlatitude']<45 ]\n",
    "# citiDataRaw = citiDataRaw[citiDataRaw['startstationlongitude']< -73 ]\n",
    "# citiDataRaw = citiDataRaw[citiDataRaw['endstationlongitude']< -73]\n",
    "#                           # need to run\n",
    "# citiDataRaw = citiDataRaw[citiDataRaw['endstationlatitude']>40 ]\n",
    "# citiDataRaw = citiDataRaw[citiDataRaw['startstationlatitude']>40 ]\n",
    "# citiDataRaw = citiDataRaw[citiDataRaw['startstationlongitude']>-75 ]\n",
    "# citiDataRaw = citiDataRaw[citiDataRaw['endstationlongitude']>-75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'citiDataRaw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3309f8095697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcitiDataRaw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendstationlatitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'citiDataRaw' is not defined"
     ]
    }
   ],
   "source": [
    "citiDataRaw.endstationlatitude.sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## see the station dock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**516 station with dock number, 825 total station. In the following code, we seperate the dock and then in phrase two, we put the dock back.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For checking, do not need to run in whole dataframe\n",
    "# a = citiDataRaw[['startstationid','starttotaldocks']][citiDataRaw.starttotaldocks>0.0].\\\n",
    "# groupby('startstationid').mean()\n",
    "# print(a.shape)\n",
    "# a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check precipAccumulation\n",
    "# #For checking, do not need to run in whole dataframe\n",
    "# a = citiDataRaw[['startstationid','precipAccumulation']].groupby('startstationid').mean()\n",
    "# print(a.shape)\n",
    "# a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run\n",
    "# #replace prepAccumulation NaN to 0\n",
    "# citiDataRaw['precipAccumulation'] = citiDataRaw.precipAccumulation.replace(np.nan, 0)\n",
    "# a = citiDataRaw[['startstationid','precipAccumulation']].groupby('startstationid').mean()\n",
    "# a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run\n",
    "# #replace prepAccumulation NaN to 0\n",
    "# #citiDataRaw[''] = citiDataRaw.precipAccumulation.replace(np.nan, 0)\n",
    "# a = citiDataRaw[['startstationid','precipIntensity']].groupby('startstationid').mean()\n",
    "# a.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipcode = pd.read_csv('citibikezipcode.csv')\n",
    "# zipcode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citiDataRaw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run\n",
    "# cols = []\n",
    "# CitiBikeData = citiDataRaw[['starttime','stoptime', 'startstationid', 'endstationid','startdate', 'datetime',\n",
    "#                            'apparentTemperature', 'cloudCover', 'humidity', 'icon' ,'precipAccumulation',\n",
    "#                             'precipIntensity', 'temperature', 'uvIndex', 'visibility', 'windSpeed',\n",
    "#                            'date', 'Holiday', 'year', 'month', 'weekday', 'starthour', 'endhour']]\n",
    "\n",
    "\n",
    "\n",
    "# CitiBikeData.columns = ['start_time','stop_time', 'start_station_id', 'end_station_id','start_date', 'datetime',\n",
    "#                            'apparent_temperature', 'cloud_cover', 'humidity', 'icon' ,'precipAccumulation',\n",
    "#                             'precip_intensity', 'temperature', 'uv_index', 'visibility', 'wind_speed',\n",
    "#                            'date', 'holiday', 'year', 'month', 'weekday', 'start_hour', 'end_hour']\n",
    "# CitiBikeData.dropna(inplace = True)\n",
    "\n",
    "# # print(CitiBikeData.dtypes)\n",
    "# CitiBikeData.head()\n",
    "\n",
    "# #CitiBikeData.describe()\n",
    "# # CitiBikeData.isnull().sum(axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CitiBikeData['start_time']= pd.to_datetime(CitiBikeData['start_time'])\n",
    "# CitiBikeData['stop_time']= pd.to_datetime(CitiBikeData['stop_time'])\n",
    "# # CitiBikeData['datetime']= pd.to_datetime(CitiBikeData['datetime'])\n",
    "\n",
    "# CitiBikeData['start_station_id'] = CitiBikeData['start_station_id'].astype('int64')\n",
    "# CitiBikeData['end_station_id'] = CitiBikeData['end_station_id'].astype('int64')\n",
    "# print(CitiBikeData.shape)\n",
    "# CitiBikeData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = pd.merge(CitiBikeData,zipcode,right_on = 'startstatid',left_on = 'start_station_id')\n",
    "# print(new.columns)\n",
    "# new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = new[new.NJ==0]\n",
    "# new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rentFreq = CitiBikeData[['start_station_id', 'datetime']]\n",
    "# rentFreq = rentFreq.groupby(['start_station_id', 'datetime']).size().to_frame().reset_index()\n",
    "\n",
    "# returnFreq = CitiBikeData[['end_station_id', 'datetime']]\n",
    "# returnFreq = returnFreq.groupby(['end_station_id', 'datetime']).size().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returnFreq.columns = ['station_id', 'datetime', 'return_freq']\n",
    "# rentFreq.columns = ['station_id', 'datetime', 'rent_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.merge(rentFreq, \n",
    "#                CitiBikeData, \n",
    "#                left_on=['station_id', 'datetime'], \n",
    "#                right_on=['start_station_id', 'datetime'])\n",
    "\n",
    "# res = pd.merge(returnFreq, \n",
    "#                res, \n",
    "#                left_on=['station_id', 'datetime'], \n",
    "#                right_on=['end_station_id', 'datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [ 'rent_freq', 'start_station_id', 'return_freq', \n",
    "#                            'apparent_temperature', 'cloud_cover', 'humidity', 'icon' ,'precipAccumulation',\n",
    "#                             'precip_intensity', 'temperature', 'uv_index', 'visibility', 'wind_speed',\n",
    "#                             'holiday',  'weekday']\n",
    "\n",
    "# # res.columns\n",
    "# res = res[cols]\n",
    "# res.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.shape\n",
    "# res.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.to_csv('train_data.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.read_csv('train_data_small.csv')\n",
    "zipcode = pd.read_csv('citibike_zipcode.csv')\n",
    "sales_price = pd.read_csv('sales_price.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.merge(zipcode, left_on='start_station_id', right_on='startstationid', how='left')\n",
    "res = res.merge(sales_price, left_on='startzip', right_on='startzip', how='left').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['start_station_id','apparent_temperature', 'cloud_cover', \n",
    "        'humidity', 'icon' ,'precipAccumulation',\n",
    "        'precip_intensity', 'temperature', 'uv_index', 'visibility', 'wind_speed',\n",
    "        'holiday',  'weekday', 'startzip', 'startsaleprice']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rent_y = res['rent_freq'].dropna()\n",
    "return_y = res['return_freq'].dropna()\n",
    "x = res[cols].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_station_id          int64\n",
       "apparent_temperature    float64\n",
       "cloud_cover             float64\n",
       "humidity                float64\n",
       "icon                     object\n",
       "precipAccumulation      float64\n",
       "precip_intensity        float64\n",
       "temperature             float64\n",
       "uv_index                float64\n",
       "visibility              float64\n",
       "wind_speed              float64\n",
       "holiday                    bool\n",
       "weekday                  object\n",
       "startzip                float64\n",
       "startsaleprice          float64\n",
       "icon_code                  int8\n",
       "holiday_code               int8\n",
       "weekday_code               int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x['datetime'] = x['datetime'].astype('category').cat.codes\n",
    "x['icon_code'] = x['icon'].astype('category').cat.codes\n",
    "x['holiday_code'] = x['holiday'].astype('category').cat.codes\n",
    "x['weekday_code'] = x['weekday'].astype('category').cat.codes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_map = dict( zip( x['icon'], x['icon_code'] ) )\n",
    "holiday_map = dict( zip( x['holiday'], x['holiday_code'] ) )\n",
    "weekday_map = dict( zip( x['weekday'], x['weekday_code'] ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop(columns=['icon', 'holiday', 'weekday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.25)\n",
    "return_x_train, return_x_test, return_y_train, return_y_test=train_test_split(x,return_y,test_size=0.25)\n",
    "\n",
    "#log y label\n",
    "# y_test_Log = np.log1p(y_test)\n",
    "# y_train_Log = np.log1p(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(y,ypred):\n",
    "    y=np.nan_to_num(y)\n",
    "    ypred=np.nan_to_num(ypred)\n",
    "    calc=(ypred-y)**2\n",
    "    return np.sqrt(np.mean(calc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# import sklearn\n",
    "# rmsle_scorer=sklearn.metrics.make_scorer(RMSLE,greater_is_better=False)\n",
    "\n",
    "# clf_4_cs=RandomForestRegressor()\n",
    "# param={'n_estimators':[200,300,400],'max_depth':[8,9,10]}\n",
    "# grid_4_cs=GridSearchCV(clf_4_cs,param_grid=param,scoring=rmsle_scorer,cv=5,n_jobs=-1,verbose=2)\n",
    "# grid_4_cs.fit(x_train, y_train)\n",
    "# print (\"Best params\",grid_4_cs.best_params_)\n",
    "# print (\"RMSLE score for casual train %f\" %(RMSLE(y_train, grid_4_cs.predict(x_train))))\n",
    "# print (\"RMSLE score for casual test %f\" %(RMSLE(y_test, grid_4_cs.predict(x_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rent RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DO NOT RERUN!!!\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "OS = []\n",
    "# for i in range(100,500,50):\n",
    "rfr_rent = RandomForestRegressor(n_estimators=300,max_depth=10)\n",
    "\n",
    "rfr_rent.fit(x_train, y_train)\n",
    "rent_score = rfr_rent.score(x_test, y_test)\n",
    "OS.append(score)\n",
    "\n",
    "plt.gca()\n",
    "# plt.plot(np.linspace(100,500,8),OS)\n",
    "plt.plot(np.linspace(100,500,1),OS)\n",
    "plt.xlabel(\"log C\")\n",
    "plt.ylabel(\"OS accuracy\")\n",
    "plt.title(\"Accuracy vs. penalization constant (log C)\")\n",
    "plt.xlim(100,500)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_return = RandomForestRegressor(n_estimators=300,max_depth=10)\n",
    "\n",
    "rfr_return.fit(x_train, y_train)\n",
    "score = rfr.score(x_test, y_test)\n",
    "OS.append(score)\n",
    "\n",
    "plt.gca()\n",
    "# plt.plot(np.linspace(100,500,8),OS)\n",
    "plt.plot(np.linspace(100,500,1),OS)\n",
    "plt.xlabel(\"log C\")\n",
    "plt.ylabel(\"OS accuracy\")\n",
    "plt.title(\"Accuracy vs. penalization constant (log C)\")\n",
    "plt.xlim(100,500)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca()\n",
    "# plt.plot(np.linspace(100,450,8),OS,'db-')\n",
    "plt.plot(np.linspace(100,450,1),OS,'db-')\n",
    "plt.xlabel(\"n_estimator\",fontsize=14)\n",
    "plt.ylabel(\"OS accuracy\",fontsize=14)\n",
    "plt.title(\"Accuracy vs. n_estimator\",fontsize=16)\n",
    "plt.xlim(100,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# temp = res.iloc[:,1:]\n",
    "# temp['holiday'] = temp['holiday'].astype('category').cat.codes\n",
    "# x_temp = pd.get_dummies(temp)\n",
    "\n",
    "# x_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whitening+ extract precipaccumulation\n",
    "# x_temp[['apparent_temperature',\\\n",
    "#        'cloud_cover', 'humidity', 'precipAccumulation', 'precip_intensity',\\\n",
    "#        'temperature', 'uv_index', 'visibility', 'wind_speed',]] = \\\n",
    "# preprocessing.scale(x_temp[['apparent_temperature',\\\n",
    "#        'cloud_cover', 'humidity', 'precipAccumulation', 'precip_intensity',\\\n",
    "#        'temperature', 'uv_index', 'visibility', 'wind_speed',]])\n",
    "\n",
    "\n",
    "# x_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test=train_test_split(x_temp,y,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x without percipaccumulation\n",
    "#n = 300\n",
    "rfr = RandomForestRegressor(n_estimators=300,max_depth=10)\n",
    "\n",
    "rfr.fit(x_train, y_train)\n",
    "score = rfr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting on Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RERUN!!!\n",
    "#plot the accuracy\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "N = np.linspace(3000, 5000, 6)\n",
    "\n",
    "OS = []\n",
    "# for c in N:\n",
    "c = int(c)\n",
    "clf = GradientBoostingRegressor(n_estimators=2000, alpha = 0.01) \n",
    "clf.fit(x_train, y_train)\n",
    "MSE=RMSLE(y_train, clf.predict(x_train))\n",
    "OS.append(MSE)\n",
    "print(1)\n",
    "\n",
    "plt.gca()\n",
    "plt.plot(np.linspace(-10,10,1),OS)\n",
    "plt.xlabel(\"n_estimator\")\n",
    "plt.ylabel(\"OS accuracy\")\n",
    "plt.title(\"Accuracy vs. n_estimator \")\n",
    "plt.xlim(-10,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.gca()\n",
    "# plt.plot(np.linspace(3000, 5000, 6),OS,\"db-\")\n",
    "# plt.xlabel(\"n_estimator\")\n",
    "# plt.ylabel(\"OS ERROR\")\n",
    "# plt.title(\"MSE vs. n_estimator \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbm = GradientBoostingRegressor(n_estimators=5000,alpha=0.01); ### Test 0.41\n",
    "gbm.fit(x_train,y_train)\n",
    "preds = gbm.predict(X= x_test)\n",
    "\n",
    "#print (\"RMSLE Value For Gradient Boost: \",RMSLE(np.exp(y_test_Log),np.exp(preds),False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"RMSLE Value For Gradient Boost: \",RMSLE(y_test,preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# plt.imshow(confusion_matrix(y_test,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best\n",
    "from sklearn.svm import SVR\n",
    "rmsle_scorer=sklearn.metrics.make_scorer(RMSLE,greater_is_better=False)\n",
    "\n",
    "rg_svr=SVR()\n",
    "param={'C': np.logspace(-3, 2, 2), 'gamma': np.logspace(-3, 2, 2), 'kernel' :['rbf','sigmoid']}\n",
    "grid_4_cs=GridSearchCV(rg_svr,param_grid=param,scoring=rmsle_scorer,cv=5,n_jobs=-1,verbose=2)\n",
    "grid_4_cs.fit(x_train, y_train)\n",
    "print (\"Best params\",grid_4_cs.best_params_)\n",
    "print (\"RMSLE score for casual train %f\" %(RMSLE(y_train, grid_4_cs.predict(x_train))))\n",
    "print (\"RMSLE score for casual test %f\" %(RMSLE(y_test, grid_4_cs.predict(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the accuracy\n",
    "C = np.logspace(-3, 2, 6)\n",
    "OS = []\n",
    "for c in C:\n",
    "    clf = svm.SVR(kernel='sigmoid',C=c) \n",
    "    clf.fit(x_train, y_train)\n",
    "    MSE= RMSLE(y_train, grid_4_cs.predict(x_train))\n",
    "    OS.append(MSE)\n",
    "\n",
    "plt.gca()\n",
    "plt.plot(np.logspace(-3, 2, 6),OS)\n",
    "plt.xlabel(\"log C\")\n",
    "plt.ylabel(\"OS accuracy\")\n",
    "plt.title(\"Accuracy vs. penalization constant (log C)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need modified according to the previous result\n",
    "from sklearn.svm import SVR\n",
    "#need to change the kernel from Gaussian Kernel to RBM\n",
    "svr = SVR(kernel='sigmoid',C=np.log(2))#\n",
    "y_train_Log = np.log1p(y_train)\n",
    "svr.fit(x_train,y_train_Log)\n",
    "y_test_Log = np.log1p(y_test)\n",
    "preds = svr.predict(X= x_test)\n",
    "print (\"RMSLE Value For Gradient Boost: \",RMSLE(y_test,preds,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(confusion_matrix(np.exp(y_test_Log),np.exp(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dock Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-341d86d09b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mholidays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named requests"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/steven/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable = '/Users/steven/anaconda3/bin/python'\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                  *  /Users/steven/anaconda3\n",
      "ipykernel_py2            /Users/steven/anaconda3/envs/ipykernel_py2\n",
      "py27                     /Users/steven/anaconda3/envs/py27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source activate myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source activate py27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
